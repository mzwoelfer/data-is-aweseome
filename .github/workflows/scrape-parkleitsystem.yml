name: "Scrape Parkleitsystem GieÃŸen"
on:
  schedule:
    - cron: '*/5 * * * *'
defaults:
  run:
    working-directory: parkleitsystem/
jobs:
  scrape_and_save:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          sparse-checkout: |
            .github
            parkleitsystem
      - uses: actions/setup-python@v4
        with:
          python-version: '3.9'
          cache: 'pip' # caching pip dependencies
      - run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Run scraping script and save data
        run: |
          parkhouse_data=$(python3 scraping_parkleitsystem.py)
          filename="$(echo "$parkhouse_data" | jq -r .timestamp).json"
          mkdir -p data
          touch data/$filename
          echo $parkhouse_data > "data/$filename"
      - uses: peter-evans/create-pull-request@v5
        id: cpr
        branch-suffix: random
      - name: Check outputs
        if: ${{ steps.cpr.outputs.pull-request-number }}
        run: |
          echo "Pull Request Number - ${{ steps.cpr.outputs.pull-request-number }}"
      - uses: hmarr/auto-approve-action@v3
        with:
          pull-request-number: ${{ steps.cpr.outputs.pull-request-number }}
